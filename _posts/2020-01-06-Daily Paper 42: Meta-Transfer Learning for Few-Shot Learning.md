---
layout: post
title: "Daily Paper 42: Meta-Tranfer Learning for Few-Shot Learning"
description: "Notes"
categories: [CV-Meta]
tags: [Paper]
redirect_from:
  - /2020/01/06/
---

# Daily Paper 42 - Meta-Tranfer Learning for Few-Shot Learning  

## Introduction  

nndl这门课需要复现一篇论文，我选了这篇作为复现的目标论文，一是因为小样本学习是我们小组目前拟研究的方向，二是因为小样本学习需要的训练集很小，训练起来比较方便，会比较省时间，三是因为作者提供了源码出来，最后如果写不完也可以直接参考作者代码。  

这篇文章是新国大、天津大学和马普所的四位学者共同发表在CVPR2019上的，主要研究小样本学习中的元学习方法的迁移学习。目前大家都知道，小样本学习这一方向很火，而小样本学习中元学习(meta-learning)又是非常好用的一种方法，所谓的元学习，主要的目的是让搭建的神经网络自己学会如何学习，从而能够用比较小的样本来完成比较难的学习任务。元学习的中心思想是利用大量的相似的小样本任务来学习到对于一些只有少量标注样本的新任务的通用学习方式，与当今深度学习网络利用大量的数据来进行学习不同，元学习的数据规模一般较小，如果仍然采用一些深层网络架构很容易过拟合，因此元学习一般采用浅层神经网络来实现，浅层神经网络+少量的训练数据，导致元学习的训练量一般是比较少的，那么训练的结果也就没有深层的网络训练出的效果好，学习的信息也相对较少。因此作者就想解决元学习无法应用在深层神经网络这一现象，在这篇文章中，作者提出了一个新的小样本学习方法，称作元迁移学习(meta-transfer learning, MTL)，该方法最大的特点，就是能够把深层的神经网络应用在小样本学习任务中。具体而言，MTL中的meta，意味着训练多个任务，而transfer是通过学习每一个任务中DNN权重的缩放和偏移函数来实现的。此外，作者还提出了hard task(HT) meta-batch方案，作为MTL的一种有效的学习课程。作者的模型在miniImageNet和FewShot-CIFAR100两个小样本学习的benchmarks上的5class1shot和5class5shot识别任务中实现了STOA。作者还进行了隔离实验，表明无论是MTL还是HT meta-batch都有助于快速的训练收敛和高准确率。  

对于小样本学习而言，一般可以分为两种类别：数据增强与基于任务的元学习，数据增强其实算是一种曲线救国的策略，虽然提供的数据集很小，但是通过多种多样的数据增强的方式，可以将原本数量很小的数据集扩充多倍，也可以将多任务的数据合在一起进行训练，不过想一想就知道，增强的数据总归不是新的数据，很难带来新的可学习的信息，而简单的数据整合也会导致不同任务的数据集方差太大，不利于统一化的学习。那么第一种方法效果不好的情况下，大家就普遍的将视角聚焦在了第二种，也就是元学习上。正如之前提到的，元学习是一种基于任务的学习方法，它的主要目标是从学习多个任务中积累经验，其base-learning主要学习的是对每一个单独的任务的数据分布进行建模。当前的一个STOA方法Model-Agnostic Meta-Learning(MAML)就是在学习寻找一个最佳的初始化状态，从而能够快速的将base-learner适应一个新任务，这个方法具有任务不可知性，这就使得该算法可以泛化到小样本学习和无监督强化学习中。不过在作者看来，该类型的方法有两大限制，第一是这些方法经常需要一大堆相似的任务来进行元训练，这本身就违背了小样本学习的初衷；第二是每一个任务通常都会由一个低复杂度的base-learner（比如浅层神经网络）建模，无法使用一些功能更为强大的深层网络，比如resnet等等，这也就是一开始作者所想要解决的最大痛点。  

那么简要的总结一下，这篇paper主要提出了一个新的元学习方法，叫做meta-transfer learning(MTL)，利用了迁移学习和元学习的优点，使用深度网络作为base-learner，并能够使深度网络在样本很少的情况下迅速收敛，并减少了过拟合的可能性。该方法中的transfer意味着在大规模的数据上训练的DNN权重能够仅通过两个操作：Scaling and Shifting(SS)来完成到其他任务的迁移；而meta意外着这些操作的参数全部可以作为超参数来看待，在小样本数据集上进行训练。在整个过程中，训练的DNN的权重是未改变的，这就避免了所谓的“catastrophic forgetting”问题，即在适应一个新的任务的过程中忘记了之前学习的广义状态。该paper的第二个主要的贡献是提出了一个有效的元学习训练的课程，课程学习和难例挖掘都说明了一个更好的训练数据的排序可以得到更快的收敛和更强大的表现，所以作者设计了一个HT meta-batch的训练策略，提供了一个有挑战性但是又很有效的学习策略。作者用一张图来介绍了他们的方法和其他方法的不同：迁移学习是最简单的，用一个比较大的网络和比较多的数据来进行训练，然后进行微调；元学习其次，用N个模型学习N个任务，然后用第N+1个模型来训练第N+1个任务；而Meta-Batch是将这N个任务分成多个batch，在每一个batch内部都有k个任务来训练；作者的MTL模型和之前的都不同，他们是用一个DNN来训练一个模型，然后对于N个不同的任务，都通过在这一个模型上进行SS和微调来解决，而在第N+1个任务上，在该模型上用之前训练得到的SS方式和针对该任务独特的微调来进行解决；至于作者的HT Meta-Batch，则是Meta-Batch的改进版本，在每一个batch内部使用k个普通任务和k'个困难任务，在一个batch内部进行在线的重采样。  

## Related Works  

作者将小样本学习分为三种，第一种叫做度量学习，主要来学习一个相似度空间，在这个空间内对于小样本的学习是非常便利的；第二种叫做记忆网络，它主要来学习对于学习经验的储存，然后将其泛化到未见过的任务中；第三种叫做基于梯度下降的方法，这些方法都有一个特定的meta-learner，用来适应一个特定的base-learner，解决多种任务，整个meta-learner优化的完成都通过使用base-learner的验证损失来进行梯度下降。作者的方法属于第三种方法，不过作者使用了迁移学习的方式来将深度网络作为base-learner。  

对于迁移学习而言，迁移什么、怎么迁移一直是核心问题。对于深度模型，应用一个预训练模型来解决一个新的问题，一般叫做微调（fine-tune），在 大规模数据集上预训练的模型已经被证明相对于完全随机初始化的模型能够有更好的泛化性能。另一种流行的迁移学习方法是将预训练模型作为backbone，在此基础上添加高级别的函数，比如目标检测、目标识别、语义分割等。作者的mtl方法就利用了预训练权重的迁移学习，主要解决如何更好的进行深度模型权重的迁移问题。在这篇paper中，在大规模数据集上训练的深度学习网络权重就是要迁移的目标，而迁移的方法就是scaling and shifting(SS)。  

课程学习是由bengio提出的，该方法在多任务学习领域中相当流行。课程学习的思想就是有规律的将训练数据喂给模型比完全随机的喂给模型会更容易完成收敛，学习结果也更有效，泛化性能也更好。课程学习在各大领域都有过应用，就我个人就在图像、音频、视频等领域看到过各种应用了。难例挖掘一开始应用在目标检测区域，它将与ground-truth重叠的图像区域定义为hard negative样本，在这些非常具有迷惑性的数据上进行训练能够获得更高的健壮性和更好的表现。作者受该例子的启发，在线采样了更困难的任务，使得MTL能够通过训练困难的任务成长的更为迅速和强大。  

## Preliminary  

作者首先介绍了一下一些基础的知识，这对于刚开始接触元学习的我来说很有帮助，因此把这一部分也精读一下。  

元学习由两个phase组成:meta-train和meta-test，meta-train一般是一个从分布p(T)中采样的分类任务T,T叫做episode，包括一个train split T<sup>(tr)</sup>用来优化base-learner和一个test split T<sup>(te)</sup>来优化meta-learner。特别的，meta-training试图从一系列采样自p(T)的episode{T}中学习。meta-test中会有一个从没见过的新任务T<sub>unseen</sub>，它将会从meta-learner开始，适应base-learner，最终的评估是由在一系列没有见过的数据点T<sub>unseen</sub><sup>(te)</sup>上完成的。  

Meta-training phase试图去从多个episode中学习到一个meta-learner。在每一个episode中，meta-training都有一个两步的优化。第一步叫做base-learning，这一过程使用交叉熵损失来优化base-learner的参数；第二步在episode测试点上会有一个feed-forward test，test loss用来优化meta-learner的参数。具体而言，给定一个episodeT，base-learner θ<sub>T</sub>会从episode训练数据T<sup>(tr)</sup>中学习到，并生成一个相关联的损失函数L<sub>T</sub>(θ<sub>T</sub>,T<sup>(tr)</sup>)。优化完损失函数之后，base learner就有了参数θ<sub>T</sub>\~。之后，meta-learner就会使用测试损失L<sub>T</sub>(θ<sub>T</sub>\~,T<sup>(te)</sup>)来更新。经过在所有的episodes上的meta-training之后，meta-learner就由测试损失优化完成，meta-learner的更新次数等同于episode的数量。  

Meta-test phase主要去测试meta-learner在未见过的任务上的快速适应性。给定T<sub>unseen</sub>，meta-learner θ<sub>T</sub>\~通过一些方法教会base learner θ<sub>T<sub>unseen</sub></sub>去适应T<sub>unseen</sub>的目的，比如通过初始化。接下来在T<sub>unseen</sub><sup>(te)</sup>上的测试结果用来评估meta-learning方法的性能，如果有多个未见过的方法，那么就取平均值作为评估结果。  

## Methodology  

作者的pipeline主要分为三步，首先在一个大规模的数据集上训练深度神经网络，这里用的是miniImageNet，并将低等级的层作为特征提取器；之后在meta-transfer learning phase中，MTL学习SS参数供给特征提取器使用，使其能够适应新的小样本学习任务；最后是对整体学习结果的改善，作者使用的是HT batch-meta策略。  

### DNN training on large-scale data  

这一部分和普通的预训练步骤基本上是相似的，具体来说，对于一个特定的小样本学习数据集，作者将用于预训练的所有类别的数据整合起来记为数据集D，这里用的是miniImageNet，该数据集共有64个类别，每一个类别都有600张图片，所以作者就用这64×600张图片训练了一个64类的分类器。  

作者首先随机初始化了一个特征提取器大θ和一个分类器小θ，例如ResNet的一个卷积层和最后一个FC层，然后使用梯度下降同时优化这两者，损失函数使用的是之前提到过的交叉熵函数，经过这个训练过程，学习到一个特征提取器大θ，这一参数在接下来的meta-training和meta-test中会被冻结，学习到的分类器小θ将会被丢弃，因为后续的小样本任务并不是这60类，这只是一个代理任务。至此学习到了通用的model，得到了想要的特征提取器，以及完成了model的base-learner的学习。  

### Meta-transfer learning(MTL)  

作者的核心算法之一就是提出了SS操作。正常的迁移学习是对整个网络进行微调，那么也就是说整个网络的所有参数都需要学习调整，但是在小样本的情况下这很容易产生过拟合现象，因此作者就试图将这一整个卷积操作拆分称为线性操作，即缩放和偏移，相较于直接改变网络的权重，作者采用将原权重进行各种不同的线性变化（SS操作）的方式来改变权重大小，这样可以显著的减少需要学习的参数。整个过程中只需要学习SS操作的两个C×1×1×1向量即可，这使得深度学习框架下的小样本学习成为可能。  

实验过程也比较简单，只需要将整个base-learner，也就是深度网络特征提取器的权重冻结，然后训练分类器小θ，训练的过程中使用梯度下降的方法，公式为θ' <- θ - β▽<sub>β</sub>L<sub>T<sup>(tr)</sup></sub>([Θ;θ],Φ<sub>S<sub>{1,2}</sub></sub>)，注意这里的分类器θ和之前的分类器并不一样，之前的分类器已经被丢弃了，这里的分类器是小样本学习任务的分类器，class数量比较少，一般为5。θ'即为训练完毕后的最优base-learner。  

用于缩放和偏移的参数Φ<sub>S<sub>1</sub></sub>和Φ<sub>S<sub>2</sub></sub>初始化为全为1和全为0，之后使用test loss T<sup>(te)</sup>来优化，公式为Φ<sub>S<sub>i</sub></sub> =: Φ<sub>S<sub>i</sub></sub> - γ▽<sub>Φ<sub>S<sub>1</sub></sub></sub>L<sub>T<sup>(te)</sup></sub>([Θ;θ'],Φ<sub>S<sub>{1,2}</sub></sub>)，在这一步里，θ使用相同的学习率γ进行优化，公式相同。这一步中的θ'来自上一步在T<sup>(tr)</sup>上训练学习base-learner的最后一个epoch，也就是上面学习到的最优base-learner。  
最后就将训练完毕的参数Φ<sub>S<sub>1</sub></sub>和Φ<sub>S<sub>2</sub></sub>应用到冻结的特征提取器权重上，这里采用的公式为SS(X;W,b;Φ<sub>S<sub>{1,2}</sub></sub>)=(W ⊙ Φ<sub>S<sub>1</sub></sub>)X + (b + Φ<sub>S<sub>2</sub></sub>)。  

作者认为其SS操作有以下三点优点：1.这能够使得MTL能够获得深度神经网络的权重的同时迅速的收敛；2.由于不改变DNN的权重，因此避免了"灾难性忘记"现象；3.由于参数很少，因此减少了MTL在小样本场景下的过拟合问题。我感觉说来说去还是一个意思，就是能够轻量化的实现深度网络在小样本学习场景下的泛化性能。  

### Hard task(HT) meta-batch  

最后就是作者的特殊训练方法，作者尝试将每一个任务中的失败案例收集起来，然后重组数据生成更为困难的任务来进行重新训练，作者称之为“grow up through hardness”。  

首先回顾一下整个训练流程，之前提到过，每一个task T有两个splits，T<sup>(tr)</sup>和T<sup>(te)</sup>，分别用作base-learning和test。base-learner被T<sup>(tr)</sup>的loss经过多个epoch的训练进行优化，SS参数随后通过T<sup>(te)</sup>的loss进行优化，在这么一轮之后，可以得到对于M个类别的T<sup>(te)</sup>的识别准确率，这时候将准确率最低的那一类拿出来，标记为当前任务训练中最为困难的一类，也可以称之为失败的一类。那么将k个任务都过一遍之后，就可以得到k个失败类别，这时候再根据这些类别的数据重新采样任务。这里又有两种采样方法，第一种就是直接用这些失败类别所在任务的样本，第二种是使用该累呗的标签去重新采样该类别的新类，这就相当于考试找到错题之后，是直接刷错题还是把错题对应的知识点找到，然后选一道数值和形式不太一样但是对应的知识点相同的题目。作者表示实验表明第二种方法能够带来更大的实验方差，能够表现的更好。  

### Algorithm  

我一般是不在阅读论文的过程中传图片的，因为github手写markdown传图片实在是太麻烦了，但是这篇paper的两个算法非常重要，看似复杂，但是列出伪代码之后就会显得相当简单，所以我将两个算法图片上传到下面。Algorithm 1是整个流程的总结，包括训练大规模的DNN和mtl过程，以及后续的HT meta-batch。Algorithm 2是一个小样本任务内部的学习过程，这有助于对整个算法最为重要的内容的细节的理解。具体流程见下图。  

![mtl](/images/daily paper/meta-transfer-learning.png)  

## Experiments  




---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
