---
layout: post
title: "Daily Paper 42: Meta-Tranfer Learning for Few-Shot Learning"
description: "Notes"
categories: [CV-Meta]
tags: [Paper]
redirect_from:
  - /2020/01/06/
---

# Daily Paper 42 - Meta-Tranfer Learning for Few-Shot Learning  

## Introduction  

nndl这门课需要复现一篇论文，我选了这篇作为复现的目标论文，一是因为小样本学习是我们小组目前拟研究的方向，二是因为小样本学习需要的训练集很小，训练起来比较方便，会比较省时间，三是因为作者提供了源码出来，最后如果写不完也可以直接参考作者代码。  

这篇文章是新国大、天津大学和马普所的四位学者共同发表在CVPR2019上的，主要研究小样本学习中的元学习方法的迁移学习。目前大家都知道，小样本学习这一方向很火，而小样本学习中元学习(meta-learning)又是非常好用的一种方法，所谓的元学习，主要的目的是让搭建的神经网络自己学会如何学习，从而能够用比较小的样本来完成比较难的学习任务。元学习的中心思想是利用大量的相似的小样本任务来学习到对于一些只有少量标注样本的新任务的通用学习方式，与当今深度学习网络利用大量的数据来进行学习不同，元学习的数据规模一般较小，如果仍然采用一些深层网络架构很容易过拟合，因此元学习一般采用浅层神经网络来实现，浅层神经网络+少量的训练数据，导致元学习的训练量一般是比较少的，那么训练的结果也就没有深层的网络训练出的效果好，学习的信息也相对较少。因此作者就想解决元学习无法应用在深层神经网络这一现象，在这篇文章中，作者提出了一个新的小样本学习方法，称作元迁移学习(meta-transfer learning, MTL)，该方法最大的特点，就是能够把深层的神经网络应用在小样本学习任务中。具体而言，MTL中的meta，意味着训练多个任务，而transfer是通过学习每一个任务中DNN权重的缩放和偏移函数来实现的。此外，作者还提出了hard task(HT) meta-batch方案，作为MTL的一种有效的学习课程。作者的模型在miniImageNet和FewShot-CIFAR100两个小样本学习的benchmarks上的5class1shot和5class5shot识别任务中实现了STOA。作者还进行了隔离实验，表明无论是MTL还是HT meta-batch都有助于快速的训练收敛和高准确率。  

对于小样本学习而言，一般可以分为两种类别：数据增强与基于任务的元学习，数据增强其实算是一种曲线救国的策略，虽然提供的数据集很小，但是通过多种多样的数据增强的方式，可以将原本数量很小的数据集扩充多倍，也可以将多任务的数据合在一起进行训练，不过想一想就知道，增强的数据总归不是新的数据，很难带来新的可学习的信息，而简单的数据整合也会导致不同任务的数据集方差太大，不利于统一化的学习。那么第一种方法效果不好的情况下，大家就普遍的将视角聚焦在了第二种，也就是元学习上。正如之前提到的，元学习是一种基于任务的学习方法，它的主要目标是从学习多个任务中积累经验，其base-learning主要学习的是对每一个单独的任务的数据分布进行建模。当前的一个STOA方法Model-Agnostic Meta-Learning(MAML)就是在学习寻找一个最佳的初始化状态，从而能够快速的将base-learner适应一个新任务，这个方法具有任务不可知性，这就使得该算法可以泛化到小样本学习和无监督强化学习中。不过在作者看来，该类型的方法有两大限制，第一是这些方法经常需要一大堆相似的任务来进行元训练，这本身就违背了小样本学习的初衷；第二是每一个任务通常都会由一个低复杂度的base-learner（比如浅层神经网络）建模，无法使用一些功能更为强大的深层网络，比如resnet等等，这也就是一开始作者所想要解决的最大痛点。  

那么简要的总结一下，这篇paper主要提出了一个新的元学习方法，叫做meta-transfer learning(MTL)，利用了迁移学习和元学习的优点，使用深度网络作为base-learner，并能够使深度网络在样本很少的情况下迅速收敛，并减少了过拟合的可能性。该方法中的transfer意味着在大规模的数据上训练的DNN权重能够仅通过两个操作：Scaling and Shifting(SS)来完成到其他任务的迁移；而meta意外着这些操作的参数全部可以作为超参数来看待，在小样本数据集上进行训练。在整个过程中，训练的DNN的权重是未改变的，这就避免了所谓的“catastrophic forgetting”问题，即在适应一个新的任务的过程中忘记了之前学习的广义状态。该paper的第二个主要的贡献是提出了一个有效的元学习训练的课程，课程学习和难例挖掘都说明了一个更好的训练数据的排序可以得到更快的收敛和更强大的表现，所以作者设计了一个HT meta-batch的训练策略，提供了一个有挑战性但是又很有效的学习策略。作者用一张图来介绍了他们的方法和其他方法的不同：迁移学习是最简单的，用一个比较大的网络和比较多的数据来进行训练，然后进行微调；元学习其次，用N个模型学习N个任务，然后用第N+1个模型来训练第N+1个任务；而Meta-Batch是将这N个任务分成多个batch，在每一个batch内部都有k个任务来训练；作者的MTL模型和之前的都不同，他们是用一个DNN来训练一个模型，然后对于N个不同的任务，都通过在这一个模型上进行SS和微调来解决，而在第N+1个任务上，在该模型上用之前训练得到的SS方式和针对该任务独特的微调来进行解决；至于作者的HT Meta-Batch，则是Meta-Batch的改进版本，在每一个batch内部使用k个普通任务和k'个困难任务，在一个batch内部进行在线的重采样。  

## Related Works  

作者将小样本学习分为三种，第一种叫做度量学习，主要来学习一个相似度空间，在这个空间内对于小样本的学习是非常便利的；第二种叫做记忆网络，它主要来学习对于学习经验的储存，然后将其泛化到未见过的任务中；第三种叫做基于梯度下降的方法，这些方法都有一个特定的meta-learner，用来适应一个特定的base-learner，解决多种任务，整个meta-learner优化的完成都通过使用base-learner的验证损失来进行梯度下降。作者的方法属于第三种方法，不过作者使用了迁移学习的方式来将深度网络作为base-learner。  

对于迁移学习而言，迁移什么、怎么迁移一直是核心问题。对于深度模型，应用一个预训练模型来解决一个新的问题，一般叫做微调（fine-tune），在 大规模数据集上预训练的模型已经被证明相对于完全随机初始化的模型能够有更好的泛化性能。另一种流行的迁移学习方法是将预训练模型作为backbone，在此基础上添加高级别的函数，比如目标检测、目标识别、语义分割等。作者的mtl方法就利用了预训练权重的迁移学习，主要解决如何更好的进行深度模型权重的迁移问题。在这篇paper中，在大规模数据集上训练的深度学习网络权重就是要迁移的目标，而迁移的方法就是scaling and shifting(SS)。  

课程学习是由bengio提出的，该方法在多任务学习领域中相当流行。课程学习的思想就是有规律的将训练数据喂给模型比完全随机的喂给模型会更容易完成收敛，学习结果也更有效，泛化性能也更好。课程学习在各大领域都有过应用，就我个人就在图像、音频、视频等领域看到过各种应用了。难例挖掘一开始应用在目标检测区域，它将与ground-truth重叠的图像区域定义为hard negative样本，在这些非常具有迷惑性的数据上进行训练能够获得更高的健壮性和更好的表现。作者受该例子的启发，在线采样了更困难的任务，使得MTL能够通过训练困难的任务成长的更为迅速和强大。  

## Preliminary  

作者首先介绍了一下一些基础的知识，这对于刚开始接触元学习的我来说很有帮助，因此把这一部分也精读一下。  

元学习由两个phase组成:meta-train和meta-test，meta-train一般是一个从分布p(T)中采样的分类任务T,T叫做episode，包括一个train split T<sup>(tr)</sup>用来优化base-learner和一个test split T<sup>(te)</sup>来优化meta-learner。特别的，meta-training试图从一系列采样自p(T)的episode{T}中学习。meta-test中会有一个从没见过的新任务T<sub>unseen</sub>，它将会从meta-learner开始，适应base-learner，最终的评估是由在一系列没有见过的数据点T<sub>unseen</sub><sup>(te)</sup>上完成的。  

Meta-training phase试图去从多个episode中学习到一个meta-learner。在每一个episode中，meta-training都有一个两步的优化。第一步叫做base-learning，这一过程使用交叉熵损失来优化base-learner的参数；第二步在episode测试点上会有一个feed-forward test，test loss用来优化meta-learner的参数。具体而言，给定一个episodeT，base-learner θ<sub>T</sub>会从episode训练数据T<sup>(tr)</sup>中学习到，并生成一个相关联的损失函数L<sub>T</sub>(θ<sub>T</sub>,T<sup>(tr)</sup>)。优化完损失函数之后，base learner就有了参数θ<sub>T</sub>~。之后，meta-learner就会使用测试损失L<sub>T</sub>(θ<sub>T</sub>~,T<sup>(te)</sup>)来更新。经过在所有的episodes上的meta-training之后，meta-learner就由测试损失优化完成，meta-learner的更新次数等同于episode的数量。  

Meta-test phase主要去测试meta-learner在未见过的任务上的快速适应性。给定T<sub>unseen</sub>，meta-learner θ<sub>T</sub>~通过一些方法教会base learner θ<sub>T<sub>unseen</sub></sub>去适应T<sub>unseen</sub>的目的，比如通过初始化。接下来在T<sub>unseen</sub><sup>(te)</sup>上的测试结果用来评估meta-learning方法的性能，如果有多个未见过的方法，那么就取平均值作为评估结果。  

## Methodology  


---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
