---
layout: post
title: "Daily Paper 40: Face2Face"
description: "Notes"
categories: [MMML-DeepFake]
tags: [Paper]
redirect_from:
  - /2019/11/26/
---

# Daily Paper 39 - Face2Face: Real-time Face Capture and Reenactment of RGB Videos  

## Introduction  

今天的这篇paper可谓换脸视频的先驱之一，是由纽伦堡大学、马普所和斯坦福的研究者们共同发表的，主要提出了Face2Face这一换脸模型。所有做虚假视频的研究者都不可能不知道Face2Face这一模型。所以今天就考下古，看看这篇CVPR2016上的老文章。由于这篇是考古文，所以写的简单一些。  

作者主要提出了一个新的方法，用来进行单目视频流的实时面部信息重建。源序列也是一个单目视频流，使用一个商业单目摄像头捕获。作者的目标是使源演员对目标视频的面部表情进行动画处理，并以逼真的方式重新渲染操纵的输出视频。为此，作者首先通过基于非刚性模型的捆绑来解决单目视频中面部身份恢复的欠约束问题。在运行时，作者使用密集的光度一致性度量来跟踪源视频和目标视频的面部表情。然后通过源和目标之间的快速且有效的变形传递来实现人脸重建。从目标序列中检索与重新定位的表情最为匹配的嘴内部并且扭曲以产生准确的结果。最后，作者在相应的视频流顶部重新渲染合成新的可信的目标人脸，使其与现实世界的照明无缝融合。  

在本文中，作者采用了基于单目RGB数据的新的密集无标记面部表现捕获方法，类似于STOA方法。然而，作者的主要贡献是实时单目面部重演，而不是将面部表情转移到虚拟CG角色。与以前的重演方法相比，作者的目标是将由RGB传感器捕获的源演员的面部表情在线转移到目标演员。目标序列可以是任何单目视频，例如，从具有面部表现的Youtube下载的传统视频镜头。作者试图以照片般逼真的方式修改目标视频，包括一些几乎不可能注意到的细节。忠实的照片般逼真的面部重演是各种应用的基础，例如，在视频会议中，可以调整视频馈送以匹配翻译者的面部动作，或者可以令人信服地将面部视频配音为外语。  

在作者的方法中，作者首先使用基于预先记录的训练序列的新的全局非刚性基于模型的捆绑方法来重建目标参与者的形状身份。由于此预处理是在一组训练帧上全局执行的，因此作者可以解决单目视频重建常见的几何模糊问题。在运行时，作者通过基于统计面部先验的密集分析合成方法来跟踪源和目标actor的视频的表达。作者证明了其RGB跟踪精度与现有技术水平相当，即使依赖深度数据的在线跟踪方法也是如此。为了实时地将表达式从源演员传递到目标演员，作者提出了一种新的传递函数，它可以直接在使用的低维表达空间中应用变形传递。对于最终图像合成，作者使用转移的表达系数重新渲染目标的面部，并在考虑估计的环境照明的情况下将其与目标视频的背景合成。最后，作者介绍了一种新的基于图像的口腔合成方法，通过从样本序列中检索和扭曲最佳匹配的嘴形状，生成逼真的口腔内部。重要的是要注意作者保持目标口形的外观，相比之下，现有方法要么将源嘴巴区域直接复制到目标，要么渲染通用的牙齿代理（昨天看的paper就是用的牙齿代理，不过不是完全通用的），这两者都会导致不一致的结果。  

作者展示了可信度高的面部表情从源视频到目标视频的实时转移。我们使用实时设置显示结果，其中由网络摄像头捕获的源视频流用于操纵目标Youtube视频。此外，作者还与最先进的面部重演方法进行了比较，结果作者在视频质量和运行时长两方面都表现优异（该模型是第一个实时RGB面部重演方法）。总之，我们的主要贡献是：基于密集的、全局的非刚性模型的捆绑；在不受约束的实时RGB视频中进行准确的跟踪，外观和照明估计；子空间形变的独立于特定人的表情迁移；提出了一个全新的嘴型同步的方法。  

我在看这篇paper的摘要和介绍的时候一直处于严重的懵逼状态，出现了大量的未见过的英语名词，直到看到这里我突然明白过来：这篇paper用的是传统方法啊。。。没有深度学习的东西，我怎么可能看的明白。。我就将就着谷歌翻译半翻译半总结的看一下吧。。  

## Synthesis of Facial Imagery  

正文中有大量的公式，我也看不太懂，就写点简单的东西好了。作者使用多线性PCA模型。前两个维度表示面部身份，即几何形状和皮肤反射，第三维度控制面部表情。我坦诚的承认我完全看不懂这一段他想表达什么，因为他上来就弄了一大堆公式，还是与期望和概率有关的，所以这一块囿于本人数学过低，我就略过了。总之，作者定义了一个脸，然后将其参数化，公式看不懂，但是总体上一个脸的合成取决于面部模型参数α，β，δ，照明参数γ，刚性变换R，t和摄像机参数κ defining Π。向量P是这些参数的并集。  

## Energy Formulation  

能量方程由三部分组成，第一部分是合成图像和原始图像的图像一致性相似度，第二部分是面部特征对齐的相似度，第三部分是统计正则化器，三部分由三个不同的权值控制。这三部分具体怎么计算的我就不抄写计算公式了，这也不是这篇paper讨论的重点。  

## Data-parallel Optimization Strategy  

这里作者使用了数据并行优化的策略，使用一种叫做Iteratively Reweighted Least Squares(IRLS) solver的方式，将每一个循环的问题通过将norm分割为两部分转换成一个非线性的最小平方问题。这里公式还是不写了，简单来讲就是使用这种方式能够并行的处理优化问题，从而提高整体处理的效率，实现最终所要求的实时处理。  

## Non-Rigid Model-Based Bundling  

基于非刚性模型的绑定这一方法作者从一开始就开始喊，不过一直没有说明白究竟是怎么回事，这里终于进行介绍了。由于下面出现了大量不像是人话的专业术语，所以我用谷歌翻译来帮我复述。  

为了估计严重不受约束的单目图像重建场景中的参与者的身份，作者引入了一种非刚性的基于模型的捆绑方法。基于所提出的目标，作者联合估计输入视频序列的k个关键帧上的所有参数。估计的未知数是全局标识{α，β}，和内在函数κ以及未知的每帧姿势和照明参数。作者使用与模型到帧跟踪建议类似的数据并行优化策略，但联合求解整个关键帧集的正规方程。对于作者的非刚性模型的捆绑问题，相应的雅可比行列式的非零结构是块密集的。作者的PCG求解器利用非零结构来提高性能。由于所有关键帧在潜在变化的照明，表情和视角下都能观察到相同的人脸身份，因此可以将身份与所有其他问题维度牢固地分开。请注意，作者还解决了Π的固有摄像机参数，从而能够处理未校准的视频素材。  

## Expression Transfer  

还有一个重要的问题就是表情的变化，这其实是最为重要的任务之一。作者使用一种叫做子空间形变转移技术的方式来进行表情的转移。经过一系列公式的巧妙变换，作者能将这一问题转变为一个线性最小二乘问题的求解，然后通过解正规方程和奇异值分解来解决这一问题。反正我是看不懂，爱咋咋地。  

## Mouth Retrieval  

表情转移过去之后，需要合成一个具体的嘴部区域，也就是嘴部的纹理。我其实很好奇传统方法是怎么合成的，因为DL方法是基于大量训练集数据的中位数或者平均数来平均化得到的，但是这里没有任何参考如何生成正确的嘴部纹理呢？  

作者其实还是通过目标actor序列中最匹配的嘴部图像中选取的，作者假设整个目标视频中嘴部的变化已经足够完整了，那么这就相当于从一个集合中选出最合适的元素。与其他传统方法原封不动的复制不同的是，作者还会保持目标嘴型的纹理不变，这就导致最后得到的结果比固定选取源嘴型和使用通用的3D牙齿代理的方式表现更好。  

具体来讲，作者的方法首先发现了最合适的嘴部帧，这是通过一个frame-to-cluster的匹配策略和一个新的特征相似度评价指标实现的。为了增强时序的耦合度，作者还使用了一个密集的表现图来找到一个上一个检索到的嘴巴帧和目标的嘴巴帧之间的中间状态，从而使得每一帧之间没有那么突兀。当然这里就是简单提一下，具体怎么弄的因为不是我们的研究重点就不做记录了。  

## Result  

作者挑了几个STOA进行对比，结果得出几个结论：作者的模型主要有以下优势：速度快，能达到实时处理；效果好，一些细化的纹理更为真实；泛化性强，完全在线处理，能处理很多来源的视频。  

作者还说了一些局限性。1.朗伯表面和平滑照明的假设是有限的，并且可能在存在硬阴影或镜面高光的情况下导致伪影。2.也是大多数最先进的方法共有的限制，长发和胡须面部闭塞的场景具有挑战性。3.此外，作者只重建和跟踪低维混合形状模型（76个表达系数），它省略了细小的静态和瞬态表面细节。4.作者基于检索的口腔合成假定靶序列中的可见表情变化足够，但是在太短的序列上，或当目标保持静止时，该模型无法学习人类特定的口腔行为。在这种情况下，可以观察到时间混叠，因为检索到的嘴部样本的目标空间太稀疏。5.最后一个局限性来自作者的硬件设置（网络摄像头，USB和PCI），这些硬件会引入帧的小延迟。专业硬件可以解决这个问题，但我们的目标是使用商用硬件进行设置。  

## Conclusion  

总之作者搞了一个实时的换脸系统，该系统能够在RGB单目影像输入的前提下完成实时的表情转换工作，并能得到很好的转换效果。这篇文章看得我是真憋屈，这是第一篇原理部分几乎全部看不懂的paper，果然即使研究的是一个东西，用传统方法和深度学习方法还是有巨大的限制的。  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
