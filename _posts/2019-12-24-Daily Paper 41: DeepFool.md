---
layout: post
title: "Daily Paper 41: DeepFool"
description: "Notes"
categories: [CV-GAN]
tags: [Paper]
redirect_from:
  - /2019/12/24/
---

# Daily Paper 41 - DeepFool: a simple and accurate method to fool deep neural networks  

## Introduction  

`typedef 鲁棒性 健壮性`

这个月一直在写代码和准备考试，写的代码过两天会集中汇总传在github的[deeplearning-study](https://github.com/JustinYuu/Deeplearning-study)这个repo上，主要是把官方的几个tutorial跑了一遍，学了下一些官方的trick，感觉还是挺有收获的。此外之前用了一周的时间总结了一下deepfake的研究进展，链接总结在我的[Awesome-DeepFake](https://github.com/JustinYuu/Awesome-DeepFake)repo里面，还做了个PPT就当是简略版的literature review了，有时间也传在这个repo里面。deepfake的paper我略读了大几十篇，有时间再挑点好的精度+复现一遍。  

这里突然看一篇paper是因为有门课的大作业要求看一篇paper写阅读报告，这正好是我之前每天干的事情，于是就从给定的paper list里面选了一篇写一下。这里看的都是生成性对抗网络GAN方面的文章，我挑的这篇叫做DeepFool，貌似还挺出名的。  

这篇paper是我的dream school epfl的几个人发表在CVPR2016上的，主要介绍了一种简单的欺骗深度神经网络的方法。当下神经网络的发展可谓迅速，在很多图像分类问题上都有着很好的表现，但是这种神经网络架构对于一些精心设计的扰动图像来说分类效果可能并不稳定。在当下，并没有能够有效衡量深度分类器对于这种扰动的鲁棒性程度的方法，在这篇文章中，作者就试图填补该领域的这片空白，提出了一个叫做DeepFool的方法来高效的计算能够骗过深度网络的扰动，并用这种生成的扰动来定量的判断这些分类器的鲁棒性。作者的实验表明其方法在计算对抗性扰动的表现比其他算法都要好，能使得分类器更加鲁棒。  

深度神经网络在很多领域，比如生物信息学、计算机视觉、语音演讲等领域都有着STOA的表现，不过虽然表现很优秀，但正如之前所提到的，这些深度学习分类器对于数据中的对抗性扰动表现并不稳定。事实上，一些很小的扰动就可能会让判别器的输出完全不同，这里作者将引起分类器结果变化的最小扰动值定义为r，将分类器最后的输出记为k(x)，将在某一点的健壮性记作△(x:k)，而对于整个分类器的健壮性则是△(x:k)/||x||<sub>2</sub>的期望，后续进行具体的数学推理。总结一下，作者的主要贡献如下：1.提出了一个简单但有效的计算和比较不同的分类器对于对抗性扰动的鲁棒性。2.作者对其模型进行了实验，得出作者的模型相对于当前的其他模型能够更好的提升模型的健壮性，且将对抗性样本加入到训练数据上进行训练能够有效的提升训练模型的鲁棒性。3.作者还发现使用不够精确的对抗性扰动生成算法可能会使训练的方向朝着不同甚至错误的方向进行。总之作者的意思大致就是，维持现状会出现问题，其他方式也不能保证解决问题，甚至会导致问题更严重，而自己的方案能够解决这一问题，损益比还比其他类似方法更好，简直是一篇优秀的政策性辩题的一辩稿。  

## DeepFool for binary classifiers  

作者认为多分类器可以看做是多个二元分类器的整合，所以作者先讨论二元分类器，再拓宽到一般情况下的多元分类器。作者首先假设了一个简单的二元分类器，将分类器定为一个简单的仿射函数f=w<sup>T</sup>x+b，然后再泛化到所有的二元分类器中。这里作者用二维图像来表示健壮性，那么分类器的分类结果k其实就是仿射函数的值究竟是正还是负，即k(x)=sign(f(x))，所谓的函数f在某点x0的健壮性△(x0,k)，其实就是x0对仿射函数f所生成的判别超平面F={x:w<sup>T</sup>x+b=0}的距离，那么能够改变分类器的决策的最小扰动就与x0在F上的正交投影相关，如果扰动大于x0在F上的正交投影，那么f(x0+r)的符号就和f(x)符号不同，判别的结果也就不同了。这样作者就将一个分类问题转变成了一个数学问题，整个方程可以写成r(x0) := argmin||r||<sub>2</sub> subject to sign(f(x0+r)) ≠ sign(f(x0)) = -f(x0)/||w||²<sub>2</sub>w.  

如果f是广义的二元可微分类器，这里精妙之处在于作者使用了一种泛化的思想，虽然我不知道f(x)的形式是什么，我也不知道f(x)的微分究竟长什么样子，但是由于之前的线性f的投影是可求的，求得的形式也是知道的，那么作者只需要将之前的公式中的w换成泛化形式的梯度▽f(x)即可，这就用二元线性仿射函数推出了二元广义仿射函数的计算方式。不过这种单凭形式推断的方式是不够科学的，所以作者采用一种循环的方式来评价健壮性，一个非线性函数的每一极小的部分可以看做是线性函数，那么利用微分的思想，非线性函数的整体可以分成无数个线性函数来看待，那么只需要用有限多个循环来计算，再将结果汇总即可成功的处理非线性函数。具体来讲，在每一轮循环中，f都会围绕当前点x被线性化，线性分类器的最小扰动就可以通过argmin||r<sub>i</sub>||<sub>2</sub> subject to f(xi) + ▽f(xi)<sup>T</sup>r<sub>i</sub> = 0计算得出。汇总过程其实不是简单的加和，而是递进，这是因为在每一步的更新中，都会求出一个当前x的r，那么这时候的r是指针对当前x所处的切分平面而言的，所以必须将x加上求得的r，进入到下一个x的切分平面中继续利用二元线性仿射的方式进行计算，这样不断的更新，直到f(x)和f(x+r)的符号不同。在实际训练中，上述算法一般可以收敛到一个零点集F上的点，这时候一个符号是正的或者是负的，但是另一个是零，所以为了达到分类边界的另外一边，最后的扰动向量r被乘了一个超参数(1+η)，这里η取0.02，这基本上可以完全避免收敛到零点集上的情况。  

## DeepFool for multiclass classifiers  

从二元向多元的扩展最为普遍和简单的方式就是one-vs-all了，这里作者也采用了这一方式，分类器产生c个输出，这里c就是最终预测类的数量，那么就有k(x)=argmax f<sub>k</sub>(x),f<sub>k</sub>(x)是f(x)在第k个类的输出。这里作者还是从线性的多元分类器开始，扩展到一般的多元分类器。  

对于线性分类器，也就是仿射分类器来说，形式可以写成f(x)=W<sup>T</sup>x+b，那么最小的r也就是argmin||r||<sub>2</sub> s.t. ∃k: w<sub>k</sub>(x0+r) + b<sub>k</sub> ≥ w<sub>k(x0)</sub>(x0+r) + b<sub>k(x0)</sub>,其中w<sub>k</sub>是矩阵W的第k列，也就是第k类的权值。只要让判别器判别为别的结果，就等同于改变了判断的值，这样一来在超平面上的约束就大了很多。在二元分类器的超平面上，只是在超平面F一侧即可，但是这里需要在F1,F2,...Fk-1等k个类生成的k-1个超平面之间的共同一侧，这里作者举了一个k=4的例子，4个类会生成3个超平面，正好围成了一个三角形，只有在这个三角形内部才会满足最后判别的结果是正确的。那么k取任意值的时候，都会生成一个凸多边形P，整个问题就会转变成一个给定的点x0与凸多边形P的补集之间的距离，我理解的补集就是多边形外面的区域。那么我们就可以用闭合的形式来解决上述公式，显然，我们只需要确定离当前点最近的多边形边界即可，我们记为l(x0)，它可以通过以下公式计算得到：l(x0)=argmin|f<sub>k</sub>(x0)-f<sub>k(x0)</sub>(x0)|/(||w<sub>k</sub>-w<sub>k(x0)</sub>||<sub>2</sub>)，那么我们就自然而然的发现，这又回到了之前的二元定位问题，我们还是只需要对l(x0)作投影，r(x0) = |f<sub>l(x0)</sub>(x0)-f<sub>k(x0)</sub>(x0)|/(||w<sub>l(x0)</sub>-w<sub>k(x0)</sub>||<sub>2</sub>) * (w<sub>l(x0)</sub> - w<sub>k(x0)</sub>)。  

然后我们再将其推广到广义的广义的多元可微分分类器中，在二元的广义推广中，利用的微元的思想将其看做多个线性的递进推进，这里也是采取相同的策略，看做是一个微元多边形的递进过程，在每一个迭代过程中，计算当前的多边形下的dist(x<sub>i</sub>,P<sub>i</sub>)，然后迭代下去。作者认为这种类贪心的优化方法并不能保证达到最优解，但是作者在实践中观察到，他们的算法产生的扰动很小，被认为是最小扰动的良好近似。作者认为DeepFool的优化策略和现有的一些优化方法非常相似，比如二元优化方法其实就是牛顿迭代法，也叫做标准流方法，作者觉得也可以看做是一种自适应步长尺寸的梯度更新算法，至于多元优化方法，作者认为可以看做是一种序列凸规划，只不过在每一步约束都被线性化了。  

作者在进行以上实验的过程中，均使用L2范数计算扰动，但是作者认为不仅可以用L2范数，事实上作者提出的算法可以适用于p≥1的任意l<sub>p</sub>范数。  

## Experiment results  

作者在深度卷积神经网络上使用MNIST、CIFAR10和ImageNet分类数据集上训练了一下，对于MNIST数据集，作者使用了一个2FC和一个2LeNet-CNN的架构进行对比，使用SGD优化；对于CIFAR10,作者使用了一个三层的LeNet网络和一个NiN网络架构，对于ILSVRC2012,作者使用的是CaffeNet和GoogLeNet预训练模型，作者用这么多数据集和网络架构的原因就是为了更好的测试其算法在不同数据集上的欺骗表现，只要在各个数据集上都有很好的欺骗表现才能说明该算法的应用性良好。  

作者还进行了一些准备工作，比如计算了测试集上的平均鲁棒性。作者还将当时的STOA方法fast gradient sign method拉过来进行了对比，该方法的一个超参数ε需要经过一定的规则找到，作者就选择了最小值进行代替，当ε取最小值的时候能够达到90%的误判率，也就是作者拿了STOA的最好表现来进行对比了。  

作者首先测试了DeepFool在不同网络和数据集上的准确型和时间复杂度，结果发现在不同网络上的平均健壮性都很差，这恰恰说明了DeepFool的表现很好，时间复杂度也比STOA的方法小五倍，不管是时间还是准确度都很高。作者还将STOA的方法Fast gradient sign和DeepFool做对比，结果得出DeepFool使得各个网络的平均健壮性更小，这说明了DeepFool的欺骗作用更强大。  

作者还用DeepFool生成的样本进行调优，试图提高样本的健壮性，此外作者还为了对比，也用Fast gradient sign生成了一些样本用于训练，来看看哪个网络更适合调优。结果表明DeepFool能够显著的提升网络的健壮性，能提升40%-50%不等，此外提升的效果显著优于Fast gradient sign，后者甚至起到了副作用。  

## Conclusion  

总结一下，作者提出了一个新的算法DeepFool，能够计算生成性样本来欺骗STOA的分类器。作者的算法采用迭代线性化的方式进行优化，能够生成相当小的扰动，但是这些扰动足以欺骗分类器，作者在三个分类器和八个数据集上对其算法进行了测试，结果表明其算法的准确性和效率都能达到STOA。此外，由于该模型对于生成性扰动的精确估计，DeepFool能够提供一种高效且准确的方式来评判分类器的健壮性，进而通过调优来提高这些分类器的表现。总之作者的模型能够完成发现问题——评估问题——解决问题的整个步骤，还是很有价值的。  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
