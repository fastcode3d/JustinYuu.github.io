---
layout: post
title: "Daily Paper 41: DeepFool"
description: "Notes"
categories: [CV-GAN]
tags: [Paper]
redirect_from:
  - /2019/12/24/
---

# Daily Paper 41 - DeepFool: a simple and accurate method to fool deep neural networks  

## Introduction  

`typedef 鲁棒性 健壮性`

这个月一直在写代码和准备考试，写的代码过两天会集中汇总传在github的[deeplearning-study](https://github.com/JustinYuu/Deeplearning-study)这个repo上，主要是把官方的几个tutorial跑了一遍，学了下一些官方的trick，感觉还是挺有收获的。此外之前用了一周的时间总结了一下deepfake的研究进展，链接总结在我的[Awesome-DeepFake](https://github.com/JustinYuu/Awesome-DeepFake)repo里面，还做了个PPT就当是简略版的literature review了，有时间也传在这个repo里面。deepfake的paper我略读了大几十篇，有时间再挑点好的精度+复现一遍。  

这里突然看一篇paper是因为有门课的大作业要求看一篇paper写阅读报告，这正好是我之前每天干的事情，于是就从给定的paper list里面选了一篇写一下。这里看的都是生成性对抗网络GAN方面的文章，我挑的这篇叫做DeepFool，貌似还挺出名的。  

这篇paper是我的dream school epfl的几个人发表在CVPR2016上的，主要介绍了一种简单的欺骗深度神经网络的方法。当下神经网络的发展可谓迅速，在很多图像分类问题上都有着很好的表现，但是这种神经网络架构对于一些精心设计的扰动图像来说分类效果可能并不稳定。在当下，并没有能够有效衡量深度分类器对于这种扰动的鲁棒性程度的方法，在这篇文章中，作者就试图填补该领域的这片空白，提出了一个叫做DeepFool的方法来高效的计算能够骗过深度网络的扰动，并用这种生成的扰动来定量的判断这些分类器的鲁棒性。作者的实验表明其方法在计算对抗性扰动的表现比其他算法都要好，能使得分类器更加鲁棒。  

深度神经网络在很多领域，比如生物信息学、计算机视觉、语音演讲等领域都有着STOA的表现，不过虽然表现很优秀，但正如之前所提到的，这些深度学习分类器对于数据中的对抗性扰动表现并不稳定。事实上，一些很小的扰动就可能会让判别器的输出完全不同，这里作者将引起分类器结果变化的最小扰动值定义为r，将分类器最后的输出记为k(x)，将在某一点的健壮性记作△(x:k)，而对于整个分类器的健壮性则是△(x:k)/||x||<sub>2</sub>的期望，后续进行具体的数学推理。总结一下，作者的主要贡献如下：1.提出了一个简单但有效的计算和比较不同的分类器对于对抗性扰动的鲁棒性。2.作者对其模型进行了实验，得出作者的模型相对于当前的其他模型能够更好的提升模型的健壮性，且将对抗性样本加入到训练数据上进行训练能够有效的提升训练模型的鲁棒性。3.作者还发现使用不够精确的对抗性扰动生成算法可能会使训练的方向朝着不同甚至错误的方向进行。总之作者的意思大致就是，维持现状会出现问题，其他方式也不能保证解决问题，甚至会导致问题更严重，而自己的方案能够解决这一问题，损益比还比其他类似方法更好，简直是一篇优秀的政策性辩题的一辩稿。  

## DeepFool for binary classifiers  

作者认为多分类器可以看做是多个二元分类器的整合，所以作者先讨论二元分类器，再拓宽到一般情况下的多元分类器。作者首先假设了一个简单的二元分类器，将分类器定为一个简单的仿射函数f=w<sup>T</sup>x+b，然后再泛化到所有的二元分类器中。这里作者用二维图像来表示健壮性，那么分类器的分类结果k其实就是仿射函数的值究竟是正还是负，即k(x)=sign(f(x))，所谓的函数f在某点x0的健壮性△(x0,k)，其实就是x0对仿射函数f所生成的判别超平面F={x:w<sup>T</sup>x+b=0}的距离，那么能够改变分类器的决策的最小扰动就与x0在F上的正交投影相关，如果扰动大于x0在F上的正交投影，那么f(x0+r)的符号就和f(x)符号不同，判别的结果也就不同了。这样作者就将一个分类问题转变成了一个数学问题，整个方程可以写成r(x0) := argmin||r||<sub>2</sub> subject to sign(f(x0+r)) ≠ sign(f(x0)) = -f(x0)/||w||²<sub>2</sub>w.  

如果f是广义的二元可微分类器，这里精妙之处在于作者使用了一种泛化的思想，虽然我不知道f(x)的形式是什么，我也不知道f(x)的微分究竟长什么样子，但是由于之前的线性f的投影是可求的，求得的形式也是知道的，那么作者只需要将之前的公式中的w换成泛化形式的梯度▽f(x)即可，这就用二元线性仿射函数推出了二元广义仿射函数的计算方式。不过这种单凭形式推断的方式是不够科学的，所以作者采用一种循环的方式来评价健壮性，一个非线性函数的每一极小的部分可以看做是线性函数，那么利用微分的思想，非线性函数的整体可以分成无数个线性函数来看待，那么只需要用有限多个循环来计算，再将结果汇总即可成功的处理非线性函数。具体来讲，在每一轮循环中，f都会围绕当前点x被线性化，线性分类器的最小扰动就可以通过argmin||r<sub>i</sub>||<sub>2</sub> subject to f(xi) + ▽f(xi)<sup>T</sup>r<sub>i</sub> = 0计算得出。汇总过程其实不是简单的加和，而是递进，这是因为在每一步的更新中，都会求出一个当前x的r，那么这时候的r是指针对当前x所处的切分平面而言的，所以必须将x加上求得的r，进入到下一个x的切分平面中继续利用二元线性仿射的方式进行计算，这样不断的更新，直到f(x)和f(x+r)的符号不同。在实际训练中，上述算法一般可以收敛到一个零点集F上的点，这时候一个符号是正的或者是负的，但是另一个是零，所以为了达到分类边界的另外一边，最后的扰动向量r被乘了一个超参数(1+η)，这里η取0.02，这基本上可以完全避免收敛到零点集上的情况。  



---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
